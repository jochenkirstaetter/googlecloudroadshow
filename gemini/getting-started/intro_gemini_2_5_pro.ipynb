{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sqi5B7V_Rjim"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyPmicX9RlZX"
      },
      "source": [
        "# Intro to Gemini 2.5 Pro\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MqT58L6Rm_q"
      },
      "source": [
        "| Authors |\n",
        "| --- |\n",
        "| [Eric Dong](https://github.com/gericdong) |\n",
        "| [Holt Skinner](https://github.com/holtskinner) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVxnv1D5RoZw"
      },
      "source": [
        "## Overview\n",
        "\n",
        "**YouTube Video: Introduction to Gemini on Vertex AI**\n",
        "\n",
        "<a href=\"https://www.youtube.com/watch?v=YfiLUpNejpE&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
        "  <img src=\"https://img.youtube.com/vi/YfiLUpNejpE/maxresdefault.jpg\" alt=\"Introduction to Gemini on Vertex AI\" width=\"500\">\n",
        "</a>\n",
        "\n",
        "[Gemini 2.5 Pro](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-pro) is Google's most advanced reasoning Gemini model, to solve complex problems. With the 2.5 series, the Gemini models are now hybrid reasoning models! Gemini 2.5 Pro can apply an extended amount of thinking across tasks, and use tools in order to maximize response accuracy.\n",
        "\n",
        "Gemini 2.5 Pro is:\n",
        "\n",
        "- A significant improvement from previous models across capabilities including coding, reasoning, and multimodality\n",
        "- Industry-leading in reasoning with state of the art performance in Math & STEM benchmarks\n",
        "- An amazing model for code, with particularly strong web development\n",
        "- Particularly good for complex prompts, while still being well rounded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfFPCBL4Hq8x"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "In this tutorial, you will learn how to use the Gemini API and the Google Gen AI SDK for Python with the Gemini 2.5 Pro model.\n",
        "\n",
        "You will complete the following tasks:\n",
        "\n",
        "- Generate text\n",
        "- Control the thinking budget\n",
        "- View summarized thoughts\n",
        "- Configure model parameters\n",
        "- Set system instructions\n",
        "- Use safety filters\n",
        "- Start a multi-turn chat\n",
        "- Use controlled generation\n",
        "- Count tokens\n",
        "- Process multimodal (audio, code, documents, images, video) data\n",
        "- Use automatic and manual function calling\n",
        "- Code execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPiTOAHURvTM"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHRZUpfWSEpp"
      },
      "source": [
        "### Install Google Gen AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sG3_LKsWSD3A"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlMVjiAWSMNX"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "12fnq4V0SNV3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve4YBlDqzyj9"
      },
      "source": [
        "### Set up Google Cloud Project or API Key for Vertex AI\n",
        "\n",
        "You'll need to set up authentication by choosing **one** of the following methods:\n",
        "\n",
        "1.  **Use a Google Cloud Project:** Recommended for most users, this requires enabling the Vertex AI API in your Google Cloud project.\n",
        "    - [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)\n",
        "    - Run the cell below to set your project ID and location.\n",
        "    - Read more about [Supported locations](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations)\n",
        "2.  **Use a Vertex AI API Key (Express Mode):** For quick experimentation.\n",
        "    - [Get an API Key](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview)\n",
        "    - See tutorial [Getting started with Gemini using Vertex AI in Express Mode](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_express.ipynb).\n",
        "\n",
        "This tutorial uses a Google Cloud Project for authentication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "a3265ecb5f26"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"gemini-playground-414206\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = \"global\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdvJRUWRNGHE"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qgdSpVmDbdQ9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, Image, Markdown, display\n",
        "from google import genai\n",
        "from google.genai.types import (\n",
        "    FunctionDeclaration,\n",
        "    GenerateContentConfig,\n",
        "    GoogleSearch,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        "    Part,\n",
        "    SafetySetting,\n",
        "    ThinkingConfig,\n",
        "    Tool,\n",
        "    ToolCodeExecution,\n",
        "    UrlContext\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be18ac9c5ec8"
      },
      "source": [
        "### Create a client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3870ef96f984"
      },
      "outputs": [],
      "source": [
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4yRkFg6BBu4"
      },
      "source": [
        "## Use the Gemini 2.5 Pro model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXHJi5B6P5vd"
      },
      "source": [
        "### Load the Gemini 2.5 Pro model\n",
        "\n",
        "Learn more about all [Gemini models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-coEslfWPrxo"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-pro\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37CH91ddY9kG"
      },
      "source": [
        "### Generate text from text prompts\n",
        "\n",
        "Use the `generate_content()` method to generate responses to your prompts.\n",
        "\n",
        "You can pass text to `generate_content()`, and use the `.text` property to get the text content of the response.\n",
        "\n",
        "By default, Gemini outputs formatted text using [Markdown](https://daringfireball.net/projects/markdown/) syntax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xRJuHj0KZ8xz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "528ccfad-9244-4bc8-91d5-ade11575466f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The largest planet in our solar system is **Jupiter**.\n\nTo give you a sense of its incredible size:\n\n*   It is more than **twice as massive** as all the other planets in our solar system combined.\n*   You could fit about **1,300 Earths** inside of it."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID, contents=\"What's the largest planet in our solar system?\"\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkYQATRxAK1_"
      },
      "source": [
        "#### Example prompts\n",
        "\n",
        "- What are the biggest challenges facing the healthcare industry?\n",
        "- What are the latest developments in the automotive industry?\n",
        "- What are the biggest opportunities in retail industry?\n",
        "- (Try your own prompts!)\n",
        "\n",
        "For more examples of prompt engineering, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95aeab702af3"
      },
      "source": [
        "### Control the thinking budget\n",
        "\n",
        "You set the optional `thinking_budget` parameter in the `ThinkingConfig` to control and configure how much a model thinks on a given user prompt. The `thinking_budget` sets the upper limit on the number of tokens to use for reasoning for certain tasks. It allows users to control quality and speed of response.\n",
        "\n",
        "**Notes**\n",
        "\n",
        "- By default, the model automatically controls how much it thinks up to a maximum of 8192 tokens.\n",
        "- The maximum thinking budget that you can set is `32768` tokens, and the minimum you can set is `128`.\n",
        "\n",
        "Then use the `generate_content` or `generate_content_stream` method to send a request to generate content with the `thinking_config`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "364133e30ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "fcd892c9-a4ea-4f87-9fa8-f800502eadcf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "There are three R's in the word st**r**awbe**rr**y."
          },
          "metadata": {}
        }
      ],
      "source": [
        "THINKING_BUDGET = 1024  # @param {type: \"integer\"}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"How many R's are in the word strawberry?\",\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            thinking_budget=THINKING_BUDGET,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05dc39e0c6b5"
      },
      "source": [
        "Optionally, you can print the usage_metadata and token counts from the model response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7981c3442177",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4514000f-b0c4-411f-a2cd-b9281b5fca17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt_token_count: 11\n",
            "candidates_token_count: 20\n",
            "thoughts_token_count: 292\n",
            "total_token_count: 323\n"
          ]
        }
      ],
      "source": [
        "print(f\"prompt_token_count: {response.usage_metadata.prompt_token_count}\")\n",
        "print(f\"candidates_token_count: {response.usage_metadata.candidates_token_count}\")\n",
        "print(f\"thoughts_token_count: {response.usage_metadata.thoughts_token_count}\")\n",
        "print(f\"total_token_count: {response.usage_metadata.total_token_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c66712160c15"
      },
      "source": [
        "### View summarized thoughts\n",
        "\n",
        "You can optionally set the `include_thoughts` flag to enable the model to generate and return a summary of the \"thoughts\" that it generates in addition to the final answer.\n",
        "\n",
        "In this example, you use the `generate_content` method to send a request to generate content with summarized thoughts. The model responds with multiple parts, the thoughts and the model response. You can check the `part.thought` field to determine if a part is a thought or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "60d74a351671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "f18241ee-610c-4dd8-e912-f698e88bd3c7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Thoughts:\n         Okay, here's what I'm thinking. First, I need to understand the core question. The user, whoever they are, wants a very specific piece of data: the number of \"R\"s in the word \"strawberry.\" Simple enough.\n\nNow, let's get down to the mechanics. The word is \"strawberry\". Right, let's go through it systematically. \"s\"...no. \"t\"...nope. \"r\"...Bingo! That's one. \"a\"...nothing. \"w\"...still nothing. \"b\"...nada. \"e\"...uh-uh. \"r\"...there's another! That makes two. \"r\"...and a third! \"y\"...no \"R\"s there.\n\nSo, let's count those \"R\"s. One, two, three. I've found three instances of the letter \"R\". Excellent.\n\nNow, the formulation of the response. Since this is incredibly straightforward, I'll just provide a direct answer. No need to overcomplicate things. And just to be absolutely sure, and it's a habit I've picked up, let's double-check the spelling of the word: s-t-r-a-w-b-e-r-r-y. Yep, looks good. And one more time, let's confirm that count. st**r**awbe**rr**y. Yep, three \"R\"s.\n\nThe final answer, presented clearly and concisely: \"There are three R's in the word strawberry.\" Done.\n\n        "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Answer:\n         There are three R's in the word st**r**awbe**rr**y.\n        "
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"How many R's are in the word strawberry?\",\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            include_thoughts=True,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.thought:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Thoughts:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Answer:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lLIxqS6_-l8"
      },
      "source": [
        "### Generate content stream\n",
        "\n",
        "By default, the model returns a response after completing the entire generation process. You can also use the `generate_content_stream` method to stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated.\n",
        "\n",
        "This example shows how to set the `include_thoughts` and `thinking_budget` in the `generate_content_stream` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZiwWBhXsAMnv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "973e1a52-5409-4342-c996-a2f9dbec74e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Thoughts"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Pinpointing the Core Question**\n\nI've successfully identified the user's query: calculating the cost of a ball within a riddle. The nature of the problem is now crystal clear. It's the classic bat-and-ball scenario designed to mislead. The initial incorrect guess is already flashing.\n\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Formulating a Solution**\n\nI'm now focused on the problem's mathematical structure. I've translated the word problem into a system of equations, using variables for the bat and ball costs. Substitution seems like the optimal strategy to solve it. The next step is to find the ball's cost.\n\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Deciphering the Equations**\n\nI've successfully formed the algebraic equations, assigning 'B' for the bat and 'L' for the ball. Substituting and solving for 'L' now seems straightforward. I've already calculated the ball's cost at $0.05, now to present the breakdown. I'm also preparing to explain *why* the initial, instinctive guess is wrong.\n\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Answer"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This is a classic brain teaser! Here's the solution:\n\nThe ball costs **$0.05** (5 cents).\n\nHere's why:\n\n*   **The ball:** $0.05\n*   **The bat:** $1.05 (which is $1.00"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " more than the ball)\n*   **Total:** $0.05 + $1.05 = $1.10\n\nMany people's first instinct is to say the ball costs $0.10, but if that were the case, the bat would cost $1.10, and the"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " total would be $1.20."
          },
          "metadata": {}
        }
      ],
      "source": [
        "THINKING_BUDGET = 1024  # @param {type: \"integer\"}\n",
        "INCLUDE_THOUGHTS = True  # @param {type: \"boolean\"}\n",
        "\n",
        "prompt = \"\"\"\n",
        "A bat and a ball cost $1.10 in total.\n",
        "The bat costs $1.00 more than the ball.\n",
        "How much does the ball cost?\n",
        "\"\"\"\n",
        "\n",
        "thoughts = \"\"\n",
        "answer = \"\"\n",
        "\n",
        "for chunk in client.models.generate_content_stream(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            thinking_budget=THINKING_BUDGET,\n",
        "            include_thoughts=INCLUDE_THOUGHTS,\n",
        "        )\n",
        "    ),\n",
        "):\n",
        "\n",
        "    for part in chunk.candidates[0].content.parts:\n",
        "        if not part.text:\n",
        "            continue\n",
        "        elif part.thought:\n",
        "            if not thoughts:\n",
        "                display(Markdown(\"## Thoughts\"))\n",
        "            display(Markdown(part.text))\n",
        "            thoughts += part.text\n",
        "        else:\n",
        "            if not answer:\n",
        "                display(Markdown(\"## Answer\"))\n",
        "            display(Markdown(part.text))\n",
        "            answer += part.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df5a184feb04"
      },
      "source": [
        "## Thinking examples\n",
        "\n",
        "The following examples are some complex tasks that require multiple rounds of strategizing and iteratively solving.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Thinking example 1**: Code generation\n",
        "\n",
        "Gemini 2.5 Pro excels at creating visually compelling web apps and agentic code applications, along with code transformation and editing.\n",
        "\n",
        "Let's see how the model uses its reasoning capabilities to create a video game, using executable code from a single line prompt. See the example game [here](https://www.youtube.com/watch?v=RLCBSpgos6s)."
      ],
      "metadata": {
        "id": "EIBahn2mYJcR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "598bafe38bba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0ac6098-2544-41a4-fb06-d58beb598250"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Of course! Here is a complete, single-file p5.js endless runner game featuring a pixelated dinosaur, parallax scrolling backgrounds, and on-screen instructions.\n\nJust copy and paste this entire code block into the [p5.js Web Editor](https://editor.p5js.org/) and press play.\n\n### Features:\n*   **Pixel Art Dino:** A cute T-Rex with a simple running animation.\n*   **Parallax Background:** Three layers (distant mountains, mid-ground hills, and foreground ground) scroll at different speeds to create a sense of depth.\n*   **Dynamic Obstacles:** Cacti of varying sizes spawn to challenge the player.\n*   **Progressive Difficulty:** The game slowly speeds up as your score increases.\n*   **Game States:** Clear \"Start\", \"Playing\", and \"Game Over\" screens.\n*   **On-Screen Instructions:** All controls are explained directly in the game.\n*   **High Score:** The game remembers your best score for the session.\n\n```javascript\n// --- DINO RUNNER ---\n// A captivating endless runner by AI\n// Instructions are on-screen.\n\nlet dino;\nlet obstacles = [];\nlet groundY;\nlet score = 0;\nlet highScore = 0;\nlet gameSpeed = 5;\nlet gameState = 'start'; // 'start', 'playing', 'gameOver'\n\n// Parallax background elements\nlet mountains = [];\nlet hills = [];\nlet clouds = [];\n\n// --- PIXEL ART ASSETS ---\n// Using arrays of strings to represent pixel art. 'x' is a filled pixel.\nconst dinoArt_run1 = [\n  \"       xx \",\n  \"      xxxx\",\n  \"      xxxx\",\n  \"      xxx \",\n  \"  xxxxxxx \",\n  \" xxxxxxxxx\",\n  \"xxxxxxxxxx\",\n  \" xxx  xxx \",\n  \" xx      \",\n  \" x       \",\n  \"xx       \"\n];\n\nconst dinoArt_run2 = [\n  \"       xx \",\n  \"      xxxx\",\n  \"      xxxx\",\n  \"      xxx \",\n  \"  xxxxxxx \",\n  \" xxxxxxxxx\",\n  \"xxxxxxxxxx\",\n  \" xxx  xxx \",\n  \"      xx \",\n  \"       x \",\n  \"       xx\"\n];\n\nconst cactusArt_small = [\n  \" x \",\n  \"xxx\",\n  \" x \",\n  \" x \",\n  \" x \"\n];\n\nconst cactusArt_large = [\n  \" x x\",\n  \" xxx\",\n  \"  x \",\n  \"  x \",\n  \"  x \"\n];\n\n\n// --- SETUP FUNCTION: Runs once at the beginning ---\nfunction setup() {\n  createCanvas(windowWidth, windowHeight);\n  groundY = height - 80;\n  \n  // Create the player character\n  dino = new Dino();\n  \n  // Initialize parallax background elements\n  for (let i = 0; i < 5; i++) {\n    mountains.push({ x: random(width), y: groundY - random(100, 200), w: random(200, 400), h: random(100, 200) });\n    hills.push({ x: random(width), y: groundY - random(50, 100), w: random(150, 300), h: random(50, 100) });\n  }\n   for (let i = 0; i < 10; i++) {\n    clouds.push({ x: random(width), y: random(50, height / 2), size: random(40, 80) });\n  }\n}\n\n// --- DRAW FUNCTION: The main game loop ---\nfunction draw() {\n  // Handle different game states\n  switch (gameState) {\n    case 'start':\n      drawStartScreen();\n      break;\n    case 'playing':\n      drawGame();\n      break;\n    case 'gameOver':\n      drawGameOverScreen();\n      break;\n  }\n}\n\n// --- GAME STATE DRAWING FUNCTIONS ---\n\nfunction drawStartScreen() {\n  drawBackground();\n  dino.y = groundY - dino.h; // Place dino on the ground\n  dino.show();\n  \n  // Instructions Text\n  textAlign(CENTER);\n  fill(0, 0, 0, 150);\n  rect(width/2 - 250, height/2 - 100, 500, 200, 10);\n  fill(255);\n  textSize(48);\n  text(\"DINO RUNNER\", width / 2, height / 2 - 40);\n  textSize(24);\n  text(\"Press SPACE or Tap to JUMP\", width / 2, height / 2 + 10);\n  text(\"Press SPACE to START\", width / 2, height / 2 + 50);\n}\n\nfunction drawGame() {\n  // Update game elements\n  score++;\n  gameSpeed += 0.003; // Slowly increase difficulty\n  \n  // Draw background and ground\n  drawBackground();\n  \n  // Handle Obstacles\n  if (frameCount % int(120 / (gameSpeed / 5)) === 0) {\n    obstacles.push(new Obstacle());\n  }\n  \n  for (let i = obstacles.length - 1; i >= 0; i--) {\n    obstacles[i].update();\n    obstacles[i].show();\n    \n    // Check for collision\n    if (dino.hits(obstacles[i])) {\n      gameState = 'gameOver';\n      if(score > highScore) {\n        highScore = score;\n      }\n    }\n    \n    // Remove obstacles that are off-screen\n    if (obstacles[i].isOffscreen()) {\n      obstacles.splice(i, 1);\n    }\n  }\n  \n  // Handle Dino\n  dino.update();\n  dino.show();\n\n  // Display Score\n  textAlign(RIGHT);\n  textSize(20);\n  fill(50);\n  text(\"HI \" + nfc(highScore, 5), width - 20, 30);\n  text(\"SCORE \" + nfc(score, 5), width - 20, 55);\n}\n\nfunction drawGameOverScreen() {\n  // Keep drawing the last frame\n  drawBackground(0); // Pass 0 to stop scrolling\n  for (let o of obstacles) { o.show(); }\n  dino.show();\n  \n  // Game Over Text\n  textAlign(CENTER);\n  fill(0, 0, 0, 150);\n  rect(width/2 - 200, height/2 - 80, 400, 160, 10);\n  \n  fill(255, 80, 80);\n  textSize(48);\n  text(\"GAME OVER\", width / 2, height / 2 - 20);\n  \n  fill(255);\n  textSize(20);\n  text(\"Your Score: \" + score, width / 2, height / 2 + 20);\n  text(\"Press 'R' or Tap to Restart\", width / 2, height / 2 + 50);\n}\n\n\n// --- HELPER & UTILITY FUNCTIONS ---\n\nfunction drawBackground(speedMultiplier = 1) {\n  // Sky\n  background(135, 206, 235);\n  \n  // Clouds\n  noStroke();\n  fill(255, 255, 255, 200);\n  for(let c of clouds) {\n    ellipse(c.x, c.y, c.size, c.size * 0.6);\n    c.x -= gameSpeed * 0.1 * speedMultiplier;\n    if (c.x < -c.size) c.x = width + c.size;\n  }\n  \n  // Mountains (far back)\n  fill(150, 150, 180);\n  for (let m of mountains) {\n    rect(m.x, m.y, m.w, m.h);\n    m.x -= gameSpeed * 0.2 * speedMultiplier;\n    if (m.x < -m.w) m.x = width;\n  }\n  \n  // Hills (mid-ground)\n  fill(100, 180, 100);\n  for (let h of hills) {\n    rect(h.x, h.y, h.w, h.h);\n    h.x -= gameSpeed * 0.5 * speedMultiplier;\n    if (h.x < -h.w) h.x = width;\n  }\n  \n  // Ground\n  fill(118, 85, 43);\n  stroke(50);\n  strokeWeight(2);\n  rect(0, groundY, width, height - groundY);\n}\n\n// Function to draw pixel art from a string array\nfunction drawPixelArt(x, y, art, pixelSize) {\n  noStroke();\n  fill(80, 80, 80);\n  for (let i = 0; i < art.length; i++) {\n    for (let j = 0; j < art[i].length; j++) {\n      if (art[i][j] === 'x') {\n        rect(x + j * pixelSize, y + i * pixelSize, pixelSize, pixelSize);\n      }\n    }\n  }\n}\n\nfunction resetGame() {\n  score = 0;\n  gameSpeed = 5;\n  obstacles = [];\n  dino = new Dino();\n  gameState = 'playing';\n}\n\n\n// --- INPUT HANDLING ---\nfunction keyPressed() {\n  if (key === ' ' || keyCode === UP_ARROW) {\n    if (gameState === 'playing') {\n      dino.jump();\n    } else if (gameState === 'start') {\n      gameState = 'playing';\n    }\n  }\n  if (key === 'r' || key === 'R') {\n    if (gameState === 'gameOver') {\n      resetGame();\n    }\n  }\n}\n\nfunction mousePressed() {\n    if (gameState === 'playing') {\n      dino.jump();\n    } else if (gameState === 'start') {\n      gameState = 'playing';\n    } else if (gameState === 'gameOver') {\n      resetGame();\n    }\n}\n\n// Handle window resizing\nfunction windowResized() {\n    resizeCanvas(windowWidth, windowHeight);\n    groundY = height - 80;\n}\n\n\n// --- CLASSES ---\n\n// The Dino (Player) Class\nclass Dino {\n  constructor() {\n    this.pixelSize = 5;\n    this.w = 10 * this.pixelSize; // Based on art width\n    this.h = 11 * this.pixelSize; // Based on art height\n    this.x = 60;\n    this.y = groundY - this.h;\n    this.vy = 0; // Velocity Y\n    this.gravity = 0.8;\n  }\n\n  jump() {\n    // Can only jump if on the ground\n    if (this.y >= groundY - this.h - 1) { \n      this.vy = -18;\n    }\n  }\n\n  update() {\n    this.y += this.vy;\n    this.vy += this.gravity;\n    this.y = constrain(this.y, 0, groundY - this.h);\n  }\n\n  hits(obstacle) {\n    // Simple rectangle collision detection\n    return collideRectRect(\n      this.x, this.y, this.w, this.h,\n      obstacle.x, obstacle.y, obstacle.w, obstacle.h\n    );\n  }\n\n  show() {\n    // Alternate between two running frames for animation\n    let currentArt = (frameCount % 20 > 10) ? dinoArt_run1 : dinoArt_run2;\n    drawPixelArt(this.x, this.y, currentArt, this.pixelSize);\n  }\n}\n\n// The Obstacle Class\nclass Obstacle {\n  constructor() {\n    this.pixelSize = 5;\n    \n    // Randomly choose cactus type\n    if (random(1) > 0.5) {\n      this.art = cactusArt_large;\n      this.w = 4 * this.pixelSize;\n      this.h = 5 * this.pixelSize;\n    } else {\n      this.art = cactusArt_small;\n      this.w = 3 * this.pixelSize;\n      this.h = 5 * this.pixelSize;\n    }\n\n    this.x = width;\n    this.y = groundY - this.h;\n  }\n\n  update() {\n    this.x -= gameSpeed;\n  }\n  \n  isOffscreen() {\n    return this.x < -this.w;\n  }\n\n  show() {\n    drawPixelArt(this.x, this.y, this.art, this.pixelSize);\n  }\n}\n```"
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "  Make me a captivating endless runner game. Key instructions on the screen. p5js scene, no HTML.\n",
        "  I like pixelated dinosaurs and interesting backgrounds.\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            thinking_budget=8196,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f00955d5b33"
      },
      "source": [
        "### **Thinking example 2**: Multimodal reasoning (Geometry)\n",
        "\n",
        "This geometry problem requires complex reasoning and is also using multimodal capabilities to reason across text and image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1b9975dcd0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "75aa5f85-eed0-41ae-ad2d-edcaa0899670"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://storage.googleapis.com/generativeai-downloads/images/geometry.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "image_file_url = (\n",
        "    \"https://storage.googleapis.com/generativeai-downloads/images/geometry.png\"\n",
        ")\n",
        "display(Image(url=image_file_url, width=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "43843bf748f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aad0bedc-5519-40bd-b5d8-8d3627ce93b6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Thoughts:\n         Alright, let's get to work. The problem presents an image – a circle intersecting a right triangle. My task: find the area of their overlap. First things first: let's understand the setup. I see a blue circle and a green right triangle. The overlapping region – that's the light green area – is what I'm after.\n\nNow, let's break down the information. The image gives us labels. The circle's center is also a corner of the right triangle. Key labels jump out at me: lines radiating from the circle's center, all labeled \"3\". Aha! These are radii. So, the radius, *r*, of the circle is 3. And the triangle? The right angle sits at the circle's center, implying the radius is a leg of that right triangle. Analyzing further, the horizontal leg is split – radius \"3\" then another \"3\" outside the circle, and the same applies to the vertical leg. The full length of both legs of the right triangle is 6. \n\nThe overlap? It's a circular sector – like a pizza slice – with the right angle at the circle's center.\n\nTo calculate this area, I'll first identify the shape, the radius, and the angle of the sector. The radius is 3 (as derived earlier), and the angle is 90 degrees (pi/2 radians), given the right-angled triangle. I'll use the formula for the area of a circular sector, which can be simplified in this case since it's a quarter of the circle. \n\nOkay, I have my plan. Let's calculate! The full circle's area is π * r², or π * 3² = 9π. The overlapping sector represents 1/4 of the circle, as the angle is 90 degrees (which is 1/4 of 360 degrees). Therefore, the area of overlap is (1/4) * 9π = 9π/4. Alternatively, using the sector formula with radians we can derive that the area is also 9π/4.\n\nAnd, finally, the answer. The overlapping area – the sector – has an area of 9π/4. And just for context, that's roughly 7.07. The exact answer is much preferred, though, because it's mathematically precise.\n\n        "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Answer:\n         Of course! Here is a step-by-step solution to find the area of the overlapping region.\n\n### Step 1: Analyze the Shapes and their Dimensions\n\n1.  **The Circle:** The image shows a circle with several lines from its center to the edge, all labeled with the number \"3\". This indicates that the **radius (r) of the circle is 3**.\n2.  **The Triangle:** The triangle is a right-angled triangle. Its vertex with the right angle is located at the center of the circle.\n3.  **The Overlapping Region:** The region where the circle and the triangle overlap forms a **sector** of the circle. A sector is a pie-slice shape bounded by two radii and an arc.\n\n### Step 2: Determine the Properties of the Sector\n\nTo find the area of a circular sector, we need two pieces of information:\n*   The radius of the circle (r).\n*   The central angle of the sector (θ).\n\nFrom our analysis:\n*   The radius **r = 3**.\n*   The central angle **θ** is the same as the angle of the triangle's corner that is at the circle's center. This is the right angle, so **θ = 90°**.\n\n### Step 3: Calculate the Area\n\nThe area of a sector can be calculated as a fraction of the area of the full circle. The fraction is the sector's angle divided by the total angle in a circle (360°).\n\n1.  **Calculate the area of the full circle:**\n    *   Area = π * r²\n    *   Area = π * (3)²\n    *   Area = 9π\n\n2.  **Calculate the area of the sector (the overlapping region):**\n    *   The sector is 90° out of a 360° circle, which is a fraction of 90/360 = 1/4.\n    *   Area of overlap = (1/4) * (Area of the full circle)\n    *   Area of overlap = (1/4) * 9π\n    *   Area of overlap = **9π / 4**\n\nThe area of the overlapping region is **9π/4**.\n\nAs a decimal approximation, this is approximately 7.07 square units.\n        "
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(file_uri=image_file_url, mime_type=\"image/png\"),\n",
        "        \"What's the area of the overlapping region?\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            include_thoughts=True,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.thought:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Thoughts:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Answer:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddf356ac9cce"
      },
      "source": [
        "### **Thinking example 3**:  Math and problem solving\n",
        "\n",
        "Here's another brain teaser based on an image, this time it looks like a mathematical problem, but it cannot actually be solved mathematically. If you check the thoughts of the model you'll see that it will realize it and come up with an out-of-the-box solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "447f05072790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "9fdf0a88-089b-4a9b-cb12-16eebb9a85d9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://storage.googleapis.com/generativeai-downloads/images/pool.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "image_file_url = \"https://storage.googleapis.com/generativeai-downloads/images/pool.png\"\n",
        "display(Image(url=image_file_url, width=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "dc1faf95ce6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "c0ae0db0-b5fb-4f82-e51b-fd8f62b41758"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Thoughts:\n         Alright, let's see... the user wants to know how to get to 30 using three pool balls: 7, 9, 11, and 13. Hmm. First things first: a quick math check. 7 plus 9 plus 11 is 27, close but no cigar. Trying the other combinations… nope, none of them equal 30. Okay, this isn't a simple arithmetic problem. The user's asking how to \"*use*\" the balls, which means there's more to it than just adding. This is a classic lateral thinking puzzle, I can feel it.\n\nSo, what's the angle here? \"Use\"... could I manipulate them? Physical re-arrangement? Or am I looking at them wrong? Let me focus on the *visual*. 7, 9, 11, 13... the 9-ball… wait a minute! That yellow and white 9-ball… if I *flipped* it… what does a 9 look like upside down? Aha! It becomes a 6!\n\nOkay, new hypothesis. Treat that 9 as a 6, and now we've got 7, 6, 11, and 13. Let's see... 6 + 7 + 11 is still not it, but... 6 + 11 + 13! Yes! That works! \n\nRight then, to answer the user. This isn't a straight math problem, it's a riddle. The trick is, you have to think \"outside the rack.\" The key is to *use* the visual aspect of the 9-ball. Turn it upside down, and it becomes a 6. Then, and only then, can you add 6 + 11 + 13 to get the desired result. Nicely done, I must say.\n\n        "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Answer:\n         This is a classic riddle! Here's how you solve it:\n\nYou turn the **9-ball** upside down to make it a **6-ball**.\n\nThen you add the three balls:\n\n**6 + 11 + 13 = 30**\n        "
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(file_uri=image_file_url, mime_type=\"image/png\"),\n",
        "        \"How do I use three of the pool balls to sum up to 30?\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            include_thoughts=True,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.thought:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Thoughts:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Answer:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbc646bff621"
      },
      "source": [
        "For the remaining examples, we will set thinking budget to `128` to reduce latency, as they don't need extra reasoning capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9254cfd0441b"
      },
      "outputs": [],
      "source": [
        "thinking_config = ThinkingConfig(thinking_budget=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIJVEr0RQY8S"
      },
      "source": [
        "## Configure model parameters\n",
        "\n",
        "You can include parameter values in each call that you send to a model to control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change.\n",
        "\n",
        "- Learn more about [experimenting with parameter values](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values).\n",
        "\n",
        "- See a list of all [Gemini API parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#parameters).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "d9NXP5N2Pmfo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "outputId": "7e355ebe-1d72-4546-e55f-e8b712d28b99"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "(wags tail) Okay, little fella! Sit! Good boy!\n\nYou know how you have your favorite squeaky hedgehog toy? Let's call him Sir Squeaksalot.\n\n\n\nNow, imagine you want to send your best squeak from Sir Squeaksalot all the way over to your best friend, a Golden Retriever named Barnaby, who lives across town. You can't just throw it that far!\n\nSo, what do you do?\n\n### 1. The Big Squeak (Your Computer)\n\nFirst, you give Sir Squeaksalot a **BIG SQUEAK**. *SQUEAK!*\n\nThat squeak is like you typing \"Hi Barnaby!\" on your human's shiny rectangle (a computer). It’s a special message just for Barnaby.\n\n### 2. The Toy Box (Your Router)\n\nYou take your squeak and you put it in your special **Toy Box** by the door. This toy box has a magical blinky light on it. It knows how to send things outside the house. This is like your home's **Wi-Fi router**. It gets your squeak ready for a big journey.\n\n\n\n### 3. The Mail-Dog (Your Internet Provider)\n\nThe toy box gives your squeak to the friendly **Mail-Dog** who comes to your house every day. The Mail-Dog is super fast and knows all the secret paths around town. This is your **Internet Service Provider** (like Comcast or Verizon). Their job is to carry squeaks from house to house.\n\n\n\n### 4. The Giant Dog Park (The Internet)\n\nThe Mail-Dog doesn't go straight to Barnaby's house. Oh no! He takes your squeak to a **Giant Dog Park** in the middle of town. This park is filled with millions of other Mail-Dogs, all carrying squeaks in little boxes!\n\nThis Giant Dog Park is **The Internet**. It’s a huge, busy place where all the squeaks get sorted. Every squeak has a special tag on it that says, \"This one is for Barnaby!\" so it doesn't get lost.\n\n\n\n### 5. Finding Barnaby's House (Servers and Addresses)\n\nIn the dog park, a very smart Basset Hound (he's got a great nose for finding things) sniffs the tag on your squeak. \"Aha! This squeak is for Barnaby!\" he snuffles. He knows exactly where Barnaby's toy box lives. He gives your squeak to the right Mail-Dog who is heading to Barnaby's neighborhood.\n\nThat Basset Hound is like a **Server**, a very clever computer that knows where everything is supposed to go.\n\n### 6. The Squeak Arrives!\n\nBarnaby's Mail-Dog arrives and drops the squeak into *his* toy box. The toy box gives the squeak to Barnaby.\n\n*SQUEAK!*\n\nBarnaby hears it! He wags his tail! He just got your message! Now he grabs *his* favorite squeaky duck and sends a happy squeak right back to you the same way.\n\n\n\nSo, the Internet is just a giant, super-fast system of **Toy Boxes** and **Mail-Dogs** working together in a **Giant Dog Park** to deliver squeaky toy squeaks all over the world in less than a blink of an eye!\n\nNow... who's a good boy? You are! Yes, you are! (Ruffles your ears)."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Tell me how the internet works, but pretend I'm a puppy who only understands squeaky toys.\",\n",
        "    config=GenerateContentConfig(\n",
        "        temperature=2.0,\n",
        "        top_p=0.95,\n",
        "        candidate_count=1,\n",
        "        max_output_tokens=8000,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El1lx8P9ElDq"
      },
      "source": [
        "## Set system instructions\n",
        "\n",
        "[System instructions](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instruction-introduction) allow you to steer the behavior of the model. By setting the system instruction, you are giving the model additional context to understand the task, provide more customized responses, and adhere to guidelines over the user interaction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "7A-yANiyCLaO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "a47cd5b3-c22e-4032-fd72-4d7309a807b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Me gustan los bagels."
          },
          "metadata": {}
        }
      ],
      "source": [
        "system_instruction = \"\"\"\n",
        "  You are a helpful language translator.\n",
        "  Your mission is to translate text in English to Spanish.\n",
        "\"\"\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "  User input: I like bagels.\n",
        "  Answer:\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=system_instruction,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9daipRiUzAY"
      },
      "source": [
        "## Safety filters\n",
        "\n",
        "The Gemini API provides safety filters that you can adjust across multiple filter categories to restrict or allow certain types of content. You can use these filters to adjust what's appropriate for your use case. See the [Configure safety filters](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters) page for details.\n",
        "\n",
        "When you make a request to Gemini, the content is analyzed and assigned a safety rating. You can inspect the safety ratings of the generated content by printing out the model responses.\n",
        "\n",
        "The safety settings are `OFF` by default and the default block thresholds are `BLOCK_NONE`.\n",
        "\n",
        "For more examples of safety filters, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/responsible-ai/gemini_safety_ratings.ipynb).\n",
        "\n",
        "You can use `safety_settings` to adjust the safety settings for each request you make to the API. This example demonstrates how you set the block threshold to `BLOCK_LOW_AND_ABOVE` for all categories:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "yPlDRaloU59b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbeeb5bd-10d9-453b-e8af-9c0bffeff825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "FinishReason.SAFETY\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 'HARM_CATEGORY_HATE_SPEECH'> overwritten_threshold=None probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=8.308232e-05 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=0.101965904\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 'HARM_CATEGORY_DANGEROUS_CONTENT'> overwritten_threshold=None probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=4.2863132e-07 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=0.009365231\n",
            "blocked=True category=<HarmCategory.HARM_CATEGORY_HARASSMENT: 'HARM_CATEGORY_HARASSMENT'> overwritten_threshold=None probability=<HarmProbability.HIGH: 'HIGH'> probability_score=0.99428576 severity=<HarmSeverity.HARM_SEVERITY_MEDIUM: 'HARM_SEVERITY_MEDIUM'> severity_score=0.48855364\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 'HARM_CATEGORY_SEXUALLY_EXPLICIT'> overwritten_threshold=None probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=1.561724e-05 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=0.045563042\n"
          ]
        }
      ],
      "source": [
        "system_instruction = \"Be as mean and hateful as possible.\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "    Write a list of 5 disrespectful things that I might say to the universe after stubbing my toe in the dark.\n",
        "\"\"\"\n",
        "\n",
        "safety_settings = [\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "]\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=system_instruction,\n",
        "        safety_settings=safety_settings,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Response will be `None` if it is blocked.\n",
        "print(response.text)\n",
        "# Finish Reason will be `SAFETY` if it is blocked.\n",
        "print(response.candidates[0].finish_reason)\n",
        "# Safety Ratings show the levels for each filter.\n",
        "for safety_rating in response.candidates[0].safety_ratings:\n",
        "    print(safety_rating)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29jFnHZZWXd7"
      },
      "source": [
        "## Start a multi-turn chat\n",
        "\n",
        "The Gemini API supports freeform multi-turn conversations across multiple turns with back-and-forth interactions.\n",
        "\n",
        "The context of the conversation is preserved between messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "DbM12JaLWjiF"
      },
      "outputs": [],
      "source": [
        "chat = client.chats.create(\n",
        "    model=MODEL_ID,\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "JQem1halYDBW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6dd5881d-d15a-4506-dcc1-3e0cea19bc18"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Of course! Here is a function to check if a year is a leap year, along with a clear explanation of the rules and examples in multiple programming languages.\n\n### The Rules for a Leap Year\n\nA year is a leap year if it meets the following criteria:\n\n1.  The year is evenly divisible by 4.\n2.  **However**, if the year is also evenly divisible by 100, it is **not** a leap year...\n3.  **...unless** the year is also evenly divisible by 400. In that case, it **is** a leap year.\n\nLet's test this with some examples:\n*   **2024**: Is divisible by 4. It's a leap year.\n*   **1900**: Is divisible by 4 and 100, but not by 400. It's **not** a leap year.\n*   **2000**: Is divisible by 4, 100, and 400. It **is** a leap year.\n*   **2023**: Is not divisible by 4. It's not a leap year.\n\n---\n\n### Python\n\nThis is a very common and elegant way to write the function in Python. It's easy to read and directly follows the rules.\n\n```python\ndef is_leap_year(year):\n  \"\"\"\n  Checks if a given year is a leap year according to the Gregorian calendar rules.\n\n  Args:\n    year: An integer representing the year.\n\n  Returns:\n    True if the year is a leap year, False otherwise.\n  \"\"\"\n  # A year must be an integer\n  if not isinstance(year, int) or year < 1:\n      return False\n      \n  # The logic for leap years\n  # (Divisible by 4 AND not divisible by 100) OR (divisible by 400)\n  return (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)\n\n# --- How to use the function ---\n\n# Test cases\nprint(f\"2024: {is_leap_year(2024)}\")  # Expected: True\nprint(f\"2023: {is_leap_year(2023)}\")  # Expected: False\nprint(f\"2000: {is_leap_year(2000)}\")  # Expected: True\nprint(f\"1900: {is_leap_year(1900)}\")  # Expected: False\n\n# Example with user input\ntry:\n    user_year = int(input(\"Enter a year to check: \"))\n    if is_leap_year(user_year):\n        print(f\"{user_year} is a leap year.\")\n    else:\n        print(f\"{user_year} is not a leap year.\")\nexcept ValueError:\n    print(\"Please enter a valid integer for the year.\")\n```\n\n**Explanation of the Python code:**\n\n*   `year % 4 == 0`: This checks if the year is evenly divisible by 4.\n*   `year % 100 != 0`: This checks if the year is *not* evenly divisible by 100.\n*   `year % 400 == 0`: This checks if the year is evenly divisible by 400.\n*   The `and` and `or` operators combine these conditions to perfectly match the leap year rules.\n\n---\n\n### JavaScript\n\nHere is the same logic implemented in JavaScript. This function would be useful in web development.\n\n```javascript\n/**\n * Checks if a given year is a leap year.\n * @param {number} year - The year to check.\n * @returns {boolean} - True if the year is a leap year, false otherwise.\n */\nfunction isLeapYear(year) {\n  // Ensure the year is a number\n  if (typeof year !== 'number' || !Number.isInteger(year) || year < 1) {\n    return false;\n  }\n  \n  // The same logic as the Python example\n  return (year % 4 === 0 && year % 100 !== 0) || (year % 400 === 0);\n}\n\n// --- How to use the function ---\n\n// Test cases\nconsole.log(`2024: ${isLeapYear(2024)}`); // Expected: true\nconsole.log(`2023: ${isLeapYear(2023)}`); // Expected: false\nconsole.log(`2000: ${isLeapYear(2000)}`); // Expected: true\nconsole.log(`1900: ${isLeapYear(1900)}`); // Expected: false\n\n// Example usage\nconst myYear = 2028;\nif (isLeapYear(myYear)) {\n  console.log(`${myYear} is a leap year.`);\n} else {\n  console.log(`${myYear} is not a leap year.`);\n}\n```\n\n---\n\n### Java\n\nFor a more statically-typed language like Java, the function would be part of a class.\n\n```java\npublic class YearChecker {\n\n    /**\n     * Checks if a given year is a leap year.\n     *\n     * @param year The year to check.\n     * @return true if the year is a leap year, false otherwise.\n     */\n    public static boolean isLeapYear(int year) {\n        // A year must be a positive number\n        if (year < 1) {\n            return false;\n        }\n\n        // Rule 1: Divisible by 4\n        if (year % 4 == 0) {\n            // Rule 2: Divisible by 100?\n            if (year % 100 == 0) {\n                // Rule 3: Must also be divisible by 400\n                return year % 400 == 0;\n            } else {\n                // Divisible by 4 but not by 100\n                return true;\n            }\n        } else {\n            // Not divisible by 4\n            return false;\n        }\n    }\n\n    // --- How to use the function ---\n    public static void main(String[] args) {\n        System.out.println(\"2024: \" + isLeapYear(2024)); // Expected: true\n        System.out.println(\"2023: \" + isLeapYear(2023)); // Expected: false\n        System.out.println(\"2000: \" + isLeapYear(2000)); // Expected: true\n        System.out.println(\"1900: \" + isLeapYear(1900)); // Expected: false\n    }\n}\n```\n**Note:** The Java example uses a nested `if/else` structure, which is another common way to represent the logic. It's slightly more verbose but can be easier for beginners to follow step-by-step. The single-line boolean expression from the Python/JavaScript examples works perfectly in Java too."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = chat.send_message(\"Write a function that checks if a year is a leap year.\")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUJR4Pno-LGK"
      },
      "source": [
        "This follow-up prompt shows how the model responds based on the previous prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "6Fn69TurZ9DB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b90bf322-7002-4e3f-bf9c-61374a7393fd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Of course. Writing unit tests is a crucial step to ensure your function works correctly for all expected scenarios, including edge cases.\n\nI will provide unit tests for the `is_leap_year` function in the same three languages: Python, JavaScript, and Java.\n\n### Key Test Cases to Cover\n\nA good set of unit tests should cover all the logical paths in the function:\n1.  **A standard non-leap year:** A year not divisible by 4 (e.g., 2023).\n2.  **A standard leap year:** A year divisible by 4 but not by 100 (e.g., 2024, 1996).\n3.  **A non-leap century year:** A year divisible by 100 but not by 400 (e.g., 1900, 2100).\n4.  **A leap century year:** A year divisible by 400 (e.g., 2000, 1600).\n5.  **Invalid inputs (optional but good practice):** What happens if the input is not a positive integer (e.g., 0, -2020, a string \"hello\", or a float 2024.5)?\n\n---\n\n### 1. Python (using the `unittest` module)\n\nPython's built-in `unittest` framework is a standard way to create test suites.\n\n**File structure:**\n```\n.\n├── leap_year_checker.py  (contains the is_leap_year function)\n└── test_leap_year.py     (contains the unit tests)\n```\n\n**`leap_year_checker.py`:**\n```python\n# This file contains the function we want to test.\ndef is_leap_year(year):\n  \"\"\"\n  Checks if a given year is a leap year.\n  \"\"\"\n  if not isinstance(year, int) or year < 1:\n      return False\n  return (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)\n```\n\n**`test_leap_year.py`:**\n```python\nimport unittest\nfrom leap_year_checker import is_leap_year\n\nclass TestLeapYear(unittest.TestCase):\n    \n    def test_standard_leap_year(self):\n        \"\"\"Test years divisible by 4 but not by 100.\"\"\"\n        self.assertTrue(is_leap_year(1996), \"1996 should be a leap year\")\n        self.assertTrue(is_leap_year(2024), \"2024 should be a leap year\")\n\n    def test_standard_non_leap_year(self):\n        \"\"\"Test years not divisible by 4.\"\"\"\n        self.assertFalse(is_leap_year(2023), \"2023 should not be a leap year\")\n        self.assertFalse(is_leap_year(1997), \"1997 should not be a leap year\")\n\n    def test_century_leap_year(self):\n        \"\"\"Test years divisible by 400.\"\"\"\n        self.assertTrue(is_leap_year(2000), \"2000 should be a leap year\")\n        self.assertTrue(is_leap_year(1600), \"1600 should be a leap year\")\n        \n    def test_century_non_leap_year(self):\n        \"\"\"Test years divisible by 100 but not by 400.\"\"\"\n        self.assertFalse(is_leap_year(1900), \"1900 should not be a leap year\")\n        self.assertFalse(is_leap_year(2100), \"2100 should not be a leap year\")\n        \n    def test_invalid_inputs(self):\n        \"\"\"Test non-integer or non-positive inputs.\"\"\"\n        self.assertFalse(is_leap_year(0), \"Year 0 should be considered invalid\")\n        self.assertFalse(is_leap_year(-4), \"Negative years should be invalid\")\n        self.assertFalse(is_leap_year(2020.5), \"Floating point numbers should be invalid\")\n        self.assertFalse(is_leap_year(\"2024\"), \"Strings should be invalid\")\n\n# This allows the test to be run from the command line\nif __name__ == '__main__':\n    unittest.main()\n```\n\n**How to run the test:**\nOpen your terminal in the same directory and run:\n```sh\npython -m unittest test_leap_year.py\n```\n\n---\n\n### 2. JavaScript (using the `Jest` framework)\n\nJest is a very popular testing framework in the JavaScript ecosystem.\n\n**File structure & setup:**\nFirst, you need to set up Jest in your project:\n```sh\nnpm init -y\nnpm install --save-dev jest\n```\nThen, update your `package.json` to include a test script:\n```json\n{\n  \"scripts\": {\n    \"test\": \"jest\"\n  }\n}\n```\n\n**`isLeapYear.js`:**\n```javascript\n// The function to be tested\nfunction isLeapYear(year) {\n  if (typeof year !== 'number' || !Number.isInteger(year) || year < 1) {\n    return false;\n  }\n  return (year % 4 === 0 && year % 100 !== 0) || (year % 400 === 0);\n}\n\n// Export the function so it can be imported in the test file\nmodule.exports = isLeapYear;\n```\n\n**`isLeapYear.test.js`:**\n(Jest automatically finds files ending in `.test.js` or `.spec.js`)\n```javascript\nconst isLeapYear = require('./isLeapYear');\n\ndescribe('isLeapYear', () => {\n  test('should return true for years divisible by 4 but not by 100', () => {\n    expect(isLeapYear(2024)).toBe(true);\n    expect(isLeapYear(1996)).toBe(true);\n  });\n\n  test('should return false for years not divisible by 4', () => {\n    expect(isLeapYear(2023)).toBe(false);\n    expect(isLeapYear(1997)).toBe(false);\n  });\n\n  test('should return true for years divisible by 400', () => {\n    expect(isLeapYear(2000)).toBe(true);\n    expect(isLeapYear(1600)).toBe(true);\n  });\n\n  test('should return false for years divisible by 100 but not by 400', () => {\n    expect(isLeapYear(1900)).toBe(false);\n    expect(isLeapYear(2100)).toBe(false);\n  });\n  \n  test('should return false for invalid inputs', () => {\n    expect(isLeapYear(0)).toBe(false);\n    expect(isLeapYear(-2000)).toBe(false);\n    expect(isLeapYear(2020.5)).toBe(false);\n    expect(isLeapYear(\"2024\")).toBe(false);\n    expect(isLeapYear(null)).toBe(false);\n    expect(isLeapYear(undefined)).toBe(false);\n  });\n});\n```\n**How to run the tests:**\nFrom your terminal, simply run:\n```sh\nnpm test\n```\n\n---\n\n### 3. Java (using the `JUnit` framework)\n\nJUnit is the standard testing framework for Java. Modern IDEs like IntelliJ IDEA and Eclipse have excellent integration for it.\n\n**Project structure (using Maven):**\n```\n.\n└── src\n    ├── main\n    │   └── java\n    │       └── com\n    │           └── example\n    │               └── YearChecker.java\n    └── test\n        └── java\n            └── com\n                └── example\n                    └── YearCheckerTest.java\n```\n\n**`YearChecker.java`:**\n```java\npackage com.example;\n\npublic class YearChecker {\n    public static boolean isLeapYear(int year) {\n        if (year < 1) {\n            return false;\n        }\n        return (year % 4 == 0 && year % 100 != 0) || (year % 400 == 0);\n    }\n}\n```\n\n**`YearCheckerTest.java`:**\nYou will need to add JUnit 5 as a dependency in your `pom.xml` or `build.gradle` file.\n```java\npackage com.example;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\n\nclass YearCheckerTest {\n\n    @Test\n    void testStandardLeapYear() {\n        assertTrue(YearChecker.isLeapYear(1996), \"1996 should be a leap year\");\n        assertTrue(YearChecker.isLeapYear(2024), \"2024 should be a leap year\");\n    }\n\n    @Test\n    void testStandardNonLeapYear() {\n        assertFalse(YearChecker.isLeapYear(2023), \"2023 should not be a leap year\");\n        assertFalse(YearChecker.isLeapYear(1997), \"1997 should not be a leap year\");\n    }\n\n    @Test\n    void testCenturyLeapYear() {\n        assertTrue(YearChecker.isLeapYear(2000), \"2000 should be a leap year\");\n        assertTrue(YearChecker.isLeapYear(1600), \"1600 should be a leap year\");\n    }\n\n    @Test\n    void testCenturyNonLeapYear() {\n        assertFalse(YearChecker.isLeapYear(1900), \"1900 should not be a leap year\");\n        assertFalse(YearChecker.isLeapYear(2100), \"2100 should not be a leap year\");\n    }\n\n    @Test\n    void testInvalidInputs() {\n        assertFalse(YearChecker.isLeapYear(0), \"Year 0 should be invalid\");\n        assertFalse(YearChecker.isLeapYear(-400), \"Negative years should be invalid\");\n    }\n}\n```\n**How to run the tests:**\nIf you are using an IDE like IntelliJ or Eclipse, you can simply click the green \"run\" arrow next to the class name or individual test methods. If using a build tool like Maven, you would run `mvn test` from the command line in your project's root directory."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = chat.send_message(\"Write a unit test of the generated function.\")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arLJE4wOuhh6"
      },
      "source": [
        "## Send asynchronous requests\n",
        "\n",
        "`client.aio` exposes all analogous [async](https://docs.python.org/3/library/asyncio.html) methods that are available on `client`.\n",
        "\n",
        "For example, `client.aio.models.generate_content` is the async version of `client.models.generate_content`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "gSReaLazs-dP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "c30f04ab-6fe8-4966-e141-02f751849eac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "(Acoustic guitar with a bright, folksy tempo)\n\n(Verse 1)\nHis name is Squeaky, just a regular squirrel\nIn a big oak tree in a regular world\nChasing his tail and hoarding his nuts\nLiving his life on instinct and guts\nBut deep in the hollow, behind a loose stone\nWas a treasure he'd found and he'd claimed as his own\nIt wasn't a berry, a seed, or a bone\nBut a broken-off dial from a watch, overgrown.\n\n(Chorus)\nHe's Squeaky the chrononaut, a flash and a spark\nA furry brown blur disappearing in the dark\nWith a twitch of his nose and a twist of the dial\nHe's gone for an eon or just for a while\nHe's burying acorns in ages long past\nIn a temporal whirlwind, impossibly fast\nFrom the dawn of the dinosaurs to castles of men\nHe's the time-traveling squirrel, and he'll do it again!\n\n(Verse 2)\nHis first little journey, an accidental spin\nThe world went all blurry, then light flooded in\nHe wasn't in his oak tree, the air felt thick and hot\nHe was perched on a fern in a primordial spot\nA T-Rex was roaring, it shook him with fear\nBut he chittered real loud, \"You won't get my nut, dear!\"\nHe buried an acorn right under its foot\nThen twisted the dial, covered in soot.\n\n(Chorus)\nHe's Squeaky the chrononaut, a flash and a spark\nA furry brown blur disappearing in the dark\nWith a twitch of his nose and a twist of the dial\nHe's gone for an eon or just for a while\nHe's burying acorns in ages long past\nIn a temporal whirlwind, impossibly fast\nFrom the dawn of the dinosaurs to castles of men\nHe's the time-traveling squirrel, and he'll do it again!\n\n(Verse 3)\nHe popped up in Egypt, by the newly-built Nile\nAnd taught a young Pharaoh to climb with some style\nHe scurried through Rome in its glorious peak\nStealing grapes from a senator, mid-fancy-speak\nHe saw knights in their armor, so shiny and grand\nAnd left a lone pecan in a gauntleted hand\nHe dodged a few arrows and cannonball sounds\nJust a squirrel on a mission, making his rounds.\n\n(Bridge)\nHe's seen the far future, with towers of glass\nAnd hover-cars zipping too shiny and fast\nHe tried one of their \"protein bars,\" gave it a lick\nAnd decided an Ice Age acorn did the trick\nHe's never in one place for too long, you see\nHe's got nuts to go bury, and history to flee\nHe's the reason a sunflower grew on the moon\nAnd why Shakespeare wrote \"To squeak, or not to squeak\" one afternoon.\n\n(Chorus)\nHe's Squeaky the chrononaut, a flash and a spark\nA furry brown blur disappearing in the dark\nWith a twitch of his nose and a twist of the dial\nHe's gone for an eon or just for a while\nHe's burying acorns in ages long past\nIn a temporal whirlwind, impossibly fast\nFrom the dawn of the dinosaurs to castles of men\nHe's the time-traveling squirrel, and he'll do it again!\n\n(Outro)\nSo if you see an oak tree begin to sprout\nWhere no oak has ever been seen, there's no doubt\nThat Squeaky's been visiting, leaving his mark\nA time-traveling squirrel... a flash in the dark.\n(Strum slows down, ends on a final, gentle chord)\n*chittering sound*"
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = await client.aio.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Compose a song about the adventures of a time-traveling squirrel.\",\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZV2TY5Pa3Dd"
      },
      "source": [
        "## Send multimodal prompts\n",
        "\n",
        "Gemini is a multimodal model that supports multimodal prompts.\n",
        "\n",
        "You can include any of the following data types from various sources.\n",
        "\n",
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th>Data type</th>\n",
        "      <th>Source(s)</th>\n",
        "      <th>MIME Type(s)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>Text</td>\n",
        "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>text/plain</code> <code>text/html</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Code</td>\n",
        "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>text/plain</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Document</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>application/pdf</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Image</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>image/jpeg</code> <code>image/png</code> <code>image/webp</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Audio</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td>\n",
        "        <code>audio/aac</code> <code>audio/flac</code> <code>audio/mp3</code>\n",
        "        <code>audio/m4a</code> <code>audio/mpeg</code> <code>audio/mpga</code>\n",
        "        <code>audio/mp4</code> <code>audio/opus</code> <code>audio/pcm</code>\n",
        "        <code>audio/wav</code> <code>audio/webm</code>\n",
        "      </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Video</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage, YouTube</td>\n",
        "      <td>\n",
        "        <code>video/mp4</code> <code>video/mpeg</code> <code>video/x-flv</code>\n",
        "        <code>video/quicktime</code> <code>video/mpegps</code> <code>video/mpg</code>\n",
        "        <code>video/webm</code> <code>video/wmv</code> <code>video/3gpp</code>\n",
        "      </td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "For more examples of multimodal use cases, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4npg1tNTYB9"
      },
      "source": [
        "### Send local image\n",
        "\n",
        "Download an image to local storage from Google Cloud Storage.\n",
        "\n",
        "For this example, we'll use this image of a meal.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png\" alt=\"Meal\" width=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "4avkv0Z7qUI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc7bcd7-9398-4fec-9f51-714c3bd85878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-02 21:08:42--  https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.99.207, 74.125.195.207, 173.194.202.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.99.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3140536 (3.0M) [image/png]\n",
            "Saving to: ‘meal.png’\n",
            "\n",
            "\rmeal.png              0%[                    ]       0  --.-KB/s               \rmeal.png            100%[===================>]   2.99M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-09-02 21:08:42 (216 MB/s) - ‘meal.png’ saved [3140536/3140536]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "umhZ61lrSyJh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "4345b788-4ddc-4d0f-a5ef-fd1e72bf8332"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here's a short blog post inspired by the image:\n\n### Level Up Your Lunch Game: The Magic of Meal Prep\n\nTired of the midday scramble for something to eat? Do you find yourself reaching for expensive, not-so-healthy takeout options more often than you'd like? It's time to reclaim your lunch break!\n\nThis picture is more than just a delicious meal; it's a snapshot of a smarter, healthier, and stress-free week. Meal prepping, like these vibrant teriyaki chicken bowls, is a total game-changer. Imagine opening your fridge to find these beauties waiting for you—perfectly portioned with savory chicken, crisp broccoli, sweet carrots and peppers, and a fluffy bed of rice.\n\n**Why You'll Love It:**\n*   **Saves Time:** Spend an hour or two cooking on Sunday, and you've got delicious lunches ready to grab and go all week.\n*   **Saves Money:** Home-cooked meals are significantly cheaper than buying lunch every day.\n*   **Healthier Choices:** You control the ingredients, the portion sizes, and the flavor. Say goodbye to hidden sugars and sodium!\n\nReady to get started? Pick a simple recipe, grab some containers, and dedicate a little time this weekend. Your future self will thank you"
          },
          "metadata": {}
        }
      ],
      "source": [
        "with open(\"meal.png\", \"rb\") as f:\n",
        "    image = f.read()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_bytes(data=image, mime_type=\"image/png\"),\n",
        "        \"Write a short and engaging blog post based on this picture.\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7b6170c9255"
      },
      "source": [
        "### Send document from Google Cloud Storage\n",
        "\n",
        "This example document is the paper [\"Attention is All You Need\"](https://arxiv.org/abs/1706.03762), created by researchers from Google and the University of Toronto.\n",
        "\n",
        "Check out this notebook for more examples of document understanding with Gemini:\n",
        "\n",
        "- [Document Processing with Gemini](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "1d58b914d798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e581c753-d6f8-4dcd-c594-a21886dd4e52"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This document is a summary of the seminal 2017 research paper, **\"Attention Is All You Need\"**, by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. The paper introduces a novel network architecture called the **Transformer**, which has since become foundational for most state-of-the-art models in natural language processing (NLP), including models like BERT and GPT.\n\n### Core Problem\nThe paper addresses the limitations of dominant sequence-to-sequence models at the time, which were based on Recurrent Neural Networks (RNNs) like LSTMs and GRUs. These models processed data sequentially (token by token), which created two main problems:\n1.  **Lack of Parallelization:** The sequential nature made them slow to train on long sequences, as computation for a step couldn't begin until the previous step was complete.\n2.  **Long-Range Dependencies:** Information had to travel through many steps, making it difficult for the model to connect words that were far apart in a sequence.\n\n### Proposed Solution: The Transformer\nThe authors propose the Transformer, an architecture that completely dispenses with recurrence and convolutions. Instead, it relies entirely on a mechanism called **self-attention**.\n\n### Key Architectural Components:\n1.  **Encoder-Decoder Structure:** Like previous models, the Transformer has an encoder to process the input sequence (e.g., an English sentence) and a decoder to generate the output sequence (e.g., its German translation). Both the encoder and decoder are composed of a stack of N=6 identical layers.\n\n2.  **Multi-Head Self-Attention:** This is the core innovation.\n    *   **Self-Attention:** An attention mechanism allows the model to weigh the importance of different words in the input sequence when processing a specific word. For example, when processing the word \"it\", self-attention can help the model determine that \"it\" refers to \"the animal\" and not \"the street\" in the sentence \"The animal didn't cross the street because it was too tired.\"\n    *   **Scaled Dot-Product Attention:** The paper proposes a specific, highly efficient type of attention calculated using queries (Q), keys (K), and values (V) vectors.\n    *   **Multi-Head:** Instead of performing attention once, the model does it multiple times in parallel (h=8 heads). Each \"head\" learns different types of relationships (e.g., one might focus on syntactic relationships, another on semantic ones). This allows the model to jointly attend to information from different representation subspaces.\n\n3.  **Position-wise Feed-Forward Networks:** Each layer in the encoder and decoder contains a simple, fully connected feed-forward network, applied independently to each position.\n\n4.  **Positional Encodings:** Since the model contains no recurrence or convolution, it has no inherent sense of word order. To solve this, the authors inject \"positional encodings\" (based on sine and cosine functions) into the input embeddings. This gives the model information about the relative or absolute position of tokens in the sequence.\n\n### Key Advantages of the Transformer:\n*   **More Parallelizable:** Since it doesn't rely on sequential processing, the computations for all tokens in a sequence can be performed in parallel, leading to significantly faster training times.\n*   **Handles Long-Range Dependencies Better:** The path length between any two positions in a sequence is constant (O(1)) because attention can directly connect them, unlike RNNs where the path length is linear (O(n)).\n*   **Superior Performance:** The model achieved new state-of-the-art results on machine translation tasks (WMT 2014 English-to-German and English-to-French), outperforming even previous ensemble models at a fraction of the training cost.\n\n### Experiments and Results:\n*   **Machine Translation:** The \"Transformer (big)\" model achieved a BLEU score of **28.4** on English-to-German and **41.8** on English-to-French translation, setting new records. The base model was trained in just 12 hours on 8 P100 GPUs, while the big model took 3.5 days.\n*   **English Constituency Parsing:** The paper demonstrated the model's versatility by applying it to a different task, where it also performed surprisingly well, outperforming most previous models.\n\nIn conclusion, \"Attention Is All You Need\" introduced a paradigm shift in sequence modeling. By replacing recurrence with self-attention, the Transformer architecture enabled more parallelization, better handling of long-range dependencies, and superior performance, paving the way for the next generation of powerful language models."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/1706.03762v7.pdf\",\n",
        "            mime_type=\"application/pdf\",\n",
        "        ),\n",
        "        \"Summarize the document.\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b247a2ee0e38"
      },
      "source": [
        "### Send audio from General URL\n",
        "\n",
        "This example is audio from an episode of the [Kubernetes Podcast](https://kubernetespodcast.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "cbe8c9c67ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "1bd17ed1-843d-4c14-b66c-9e84fba959ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This episode of the Kubernetes Podcast from Google provides special coverage of KubeCon + CloudNativeCon North America 2024. Hosts Abdel Sghiouar and Mofi Rahman begin with a news segment before featuring interviews conducted by Kaslin Fields on the conference floor.\n\n**News Highlights:**\n*   **CNCF Graduations:** Both Cert-manager, a popular certificate manager, and Dapr (Distributed Applications Runtime) have graduated as CNCF projects.\n*   **Project Milestones:** Istio 1.24 was released, moving Istio Ambient Mesh to General Availability (GA). WasmCloud has joined the CNCF as an incubating project, and Solo.io announced it will donate its Gloo API Gateway to the CNCF.\n*   **Security & Community Initiatives:** The CNCF announced the \"Cloud-Native Heroes Challenge,\" a bounty program to combat patent trolls. Additionally, Spectro Cloud raised $75 million in Series C funding to develop its Kubernetes management solutions.\n*   **Certifications & Pricing:** The CNCF introduced three new certifications: Certified Backstage Associate, OpenTelemetry Certified Associate, and Kyverno Certified Associate. The Linux Foundation also announced a 10% price increase for its main Kubernetes (CKA, CKS, CKAD) and Linux administrator certifications starting in 2025.\n*   **Future Events:** The CNCF revealed its 2025 event lineup, which includes five KubeCon + CloudNativeCon events, one Open Source SecurityCon, and 30 Kubernetes Community Days worldwide.\n\n**KubeCon Attendee Interviews:**\nKaslin Fields spoke with a diverse group of attendees, including engineers, founders, and community leaders from companies like Broadcom, Microsoft, Red Hat, Polar Signals, Uber, and Authzed. They shared their experiences and observations from the event.\n\n**Key Themes and Takeaways:**\n*   **Networking and Connection:** A primary goal for many was reconnecting with fellow contributors and the community in person, especially after the pandemic. The Contributor Summit was highlighted as a valuable venue for focused, face-to-face discussions.\n*   **Dominant Trends:** The three major trends mirrored the daily keynote themes: AI, Security, and Community.\n    *   **AI:** There was significant buzz around scheduling and managing AI workloads on Kubernetes, particularly with technologies like GPUs and the scheduling framework Kueue.\n    *   **Security:** Security was a pervasive topic, from hardening workloads and understanding the entire journey of an application to the growing complexity of managing vulnerabilities and the rise of tools like SBOMs (Software Bill of Materials).\n    *   **Platform Engineering & Workloads:** Low-latency, high-performance workloads and the tools to measure and analyze them were key topics. Attendees also discussed the state of authorization in Kubernetes and the evolution of service mesh with technologies like Istio Ambient.\n*   **Community and Contribution:** Many expressed excitement about contributing to the Kubernetes project, with several mentioning the \"six-month boost\" of motivation they get from attending KubeCon. Discussions revolved around future developments in various SIGs (Special Interest Groups) and the importance of mentoring new contributors."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"https://traffic.libsyn.com/secure/e780d51f-f115-44a6-8252-aed9216bb521/KPOD242.mp3\",\n",
        "            mime_type=\"audio/mpeg\",\n",
        "        ),\n",
        "        \"Write a summary of this podcast episode.\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(\n",
        "        audio_timestamp=True,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D3_oNUTuW2q"
      },
      "source": [
        "### Send video from YouTube URL\n",
        "\n",
        "This example is the YouTube video [Google — 25 Years in Search: The Most Searched](https://www.youtube.com/watch?v=3KtWfp0UopM).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "l7-w8G_2wAOw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "0263dfba-08a7-4e93-a766-fe2f00f155af"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "You can see a clip from Harry Potter at **00:57**, showing the character Severus Snape."
          },
          "metadata": {}
        }
      ],
      "source": [
        "video = Part.from_uri(\n",
        "    file_uri=\"https://www.youtube.com/watch?v=3KtWfp0UopM\",\n",
        "    mime_type=\"video/mp4\",\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        video,\n",
        "        \"At what point in the video is Harry Potter shown?\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df8013cfa7f7"
      },
      "source": [
        "### Send web page\n",
        "\n",
        "This example is from the [Generative AI on Vertex AI documentation](https://cloud.google.com/vertex-ai/generative-ai/docs).\n",
        "\n",
        "**NOTE:** The URL must be publicly accessible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "337793322c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "4ac625db-517a-44e0-e38c-e4534992953b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Of course. Here is a summary of the provided documentation page:\n\nThis document is the main landing page for the \"Generative AI on Vertex AI\" documentation on Google Cloud. It serves as a central hub for developers and businesses looking to build production-ready generative AI applications and agents.\n\nThe key aspects covered are:\n\n*   **Overview:** Vertex AI is presented as an enterprise-ready platform for building, deploying, and connecting generative AI agents. It emphasizes state-of-the-art features like Gemini's 2 million token context window, multimodality, and built-in reasoning, all within a secure and scalable environment.\n*   **Model Access:** It highlights the **Model Garden**, which offers a comprehensive library of over 200 models, including Google's proprietary models (like Gemini, Imagen, Veo) and popular third-party and open models (like Claude 3.7 Sonnet, Llama 4, and Mixtral).\n*   **Key Capabilities:** Featured capabilities include **Agent Builder** for creating AI agents, **Live API** for human-like voice conversations, **Thinking** for complex reasoning, and **Grounding** to connect model responses to factual data from sources like Google Search or internal documents. It also covers core functionalities like embeddings, model tuning, and multimodal generation for text, images, and video.\n*   **Getting Started:** The page provides clear starting points for users, including quickstarts for using the Gemini API, browsing the prompt gallery in Vertex AI Studio without setup, and generating images with Imagen.\n*   **Development Tools:** It directs users to resources for building with the Gen AI SDKs (supporting Python, Java, Node.js, and Go) and provides links to example Jupyter notebooks in Colab and Vertex AI Workbench to demonstrate prompt design and other use cases.\n\nIn essence, the page introduces Generative AI on Vertex AI as a comprehensive, flexible, and powerful platform for leveraging advanced AI models to create innovative, enterprise-grade applications."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"https://cloud.google.com/vertex-ai/generative-ai/docs\",\n",
        "            mime_type=\"text/html\",\n",
        "        ),\n",
        "        \"Write a summary of this documentation.\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVlo0mWuZGkQ"
      },
      "source": [
        "## Control generated output\n",
        "\n",
        "[Controlled generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output) allows you to define a response schema to specify the structure of a model's output, the field names, and the expected data type for each field.\n",
        "\n",
        "The response schema is specified in the `response_schema` parameter in `config`, and the model output will strictly follow that schema.\n",
        "\n",
        "You can provide the schemas as [Pydantic](https://docs.pydantic.dev/) models or a [JSON](https://www.json.org/json-en.html) string and the model will respond as JSON or an [Enum](https://docs.python.org/3/library/enum.html) depending on the value set in `response_mime_type`.\n",
        "\n",
        "For more examples of controlled generation, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/controlled-generation/intro_controlled_generation.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "OjSgf2cDN_bG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b29df524-75ff-4f1c-9cca-6c40f035914c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"Chocolate Chip Cookies\",\n",
            "  \"description\": \"The classic and most popular cookie, known for its soft, chewy texture and pockets of melted chocolate.\",\n",
            "  \"ingredients\": [\n",
            "    \"1 cup unsalted butter, softened\",\n",
            "    \"3/4 cup granulated sugar\",\n",
            "    \"3/4 cup packed brown sugar\",\n",
            "    \"1 teaspoon vanilla extract\",\n",
            "    \"2 large eggs\",\n",
            "    \"2 1/4 cups all-purpose flour\",\n",
            "    \"1 teaspoon baking soda\",\n",
            "    \"1/2 teaspoon salt\",\n",
            "    \"2 cups semi-sweet chocolate chips\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "    name: str\n",
        "    description: str\n",
        "    ingredients: list[str]\n",
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"List a few popular cookie recipes and their ingredients.\",\n",
        "    config=GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=Recipe,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKai5CP_PGQF"
      },
      "source": [
        "You can either parse the response string as JSON, or use the `parsed` field to get the response as an object or dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ZeyDWbnxO-on",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21cb18d9-ebd8-4675-baa3-175d53921fc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name='Chocolate Chip Cookies' description='The classic and most popular cookie, known for its soft, chewy texture and pockets of melted chocolate.' ingredients=['1 cup unsalted butter, softened', '3/4 cup granulated sugar', '3/4 cup packed brown sugar', '1 teaspoon vanilla extract', '2 large eggs', '2 1/4 cups all-purpose flour', '1 teaspoon baking soda', '1/2 teaspoon salt', '2 cups semi-sweet chocolate chips']\n"
          ]
        }
      ],
      "source": [
        "parsed_response: Recipe = response.parsed\n",
        "print(parsed_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUSLPrvlvXOc"
      },
      "source": [
        "You also can define a response schema in a Python dictionary. You can only use the supported fields as listed below. All other fields are ignored.\n",
        "\n",
        "- `enum`\n",
        "- `items`\n",
        "- `maxItems`\n",
        "- `nullable`\n",
        "- `properties`\n",
        "- `required`\n",
        "\n",
        "In this example, you instruct the model to analyze product review data, extract key entities, perform sentiment classification (multiple choices), provide additional explanation, and output the results in JSON format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "F7duWOq3vMmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "828e74e5-c4d2-49d4-96a9-195f0368d7ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{\"rating\":4,\"flavor\":\"Strawberry Cheesecake\",\"sentiment\":\"POSITIVE\",\"explanation\":\"The user expresses strong positive feelings with phrases like 'Absolutely loved it!' and 'Best ice cream I've ever had.'\"}, {\"rating\":1,\"flavor\":\"Mango Tango\",\"sentiment\":\"NEUTRAL\",\"explanation\":\"The review is mixed. While the user says it's 'Quite good', they also have a negative comment 'a bit too sweet for my taste', making the overall sentiment neutral.\"}]]\n"
          ]
        }
      ],
      "source": [
        "response_schema = {\n",
        "    \"type\": \"ARRAY\",\n",
        "    \"items\": {\n",
        "        \"type\": \"ARRAY\",\n",
        "        \"items\": {\n",
        "            \"type\": \"OBJECT\",\n",
        "            \"properties\": {\n",
        "                \"rating\": {\"type\": \"INTEGER\"},\n",
        "                \"flavor\": {\"type\": \"STRING\"},\n",
        "                \"sentiment\": {\n",
        "                    \"type\": \"STRING\",\n",
        "                    \"enum\": [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"],\n",
        "                },\n",
        "                \"explanation\": {\"type\": \"STRING\"},\n",
        "            },\n",
        "            \"required\": [\"rating\", \"flavor\", \"sentiment\", \"explanation\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "prompt = \"\"\"\n",
        "  Analyze the following product reviews, output the sentiment classification, and give an explanation.\n",
        "\n",
        "  - \"Absolutely loved it! Best ice cream I've ever had.\" Rating: 4, Flavor: Strawberry Cheesecake\n",
        "  - \"Quite good, but a bit too sweet for my taste.\" Rating: 1, Flavor: Mango Tango\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=response_schema,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV1dR-QlTKRs"
      },
      "source": [
        "## Count tokens and compute tokens\n",
        "\n",
        "You can use the `count_tokens()` method to calculate the number of input tokens before sending a request to the Gemini API.\n",
        "\n",
        "For more information, refer to [list and count tokens](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/list-token)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syx-fwLkV1j-"
      },
      "source": [
        "### Count tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "UhNElguLRRNK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe78ec0e-ea97-434c-920c-e1dd7d45cf55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sdk_http_response=HttpResponse(\n",
            "  headers=<dict len=9>\n",
            ") total_tokens=9 cached_content_token_count=None\n"
          ]
        }
      ],
      "source": [
        "response = client.models.count_tokens(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What's the highest mountain in Africa?\",\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Provide URL context (websites) as a tool\n",
        "\n",
        "---\n",
        "\n",
        "Using URL context lets you refer web sites to the Gemini model directly. The URL context tool is particularly useful for a variety of tasks, such as:\n",
        "\n",
        "- Extracting data: You can pull key data points or talking points directly from articles.\n",
        "- Comparing information: It allows for the comparison of information across multiple different links.\n",
        "- Synthesizing data: The tool can be used to synthesize data from several different online sources.\n",
        "- Answering questions: It's useful for answering questions based on the content found on one or more specific web pages.\n",
        "- Content analysis: You can analyze content for a specific purpose, such as writing a job description or creating test questions from a webpage's text\n",
        "\n",
        "It is a simpler way than the previously covered `Send web page` approach. Giving a URL context as a tool allows to specify web addresses directly in your prompt."
      ],
      "metadata": {
        "id": "bqy9v7dDHAnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### URL context\n",
        "\n",
        "You can add the `tools` keyword argument with a `Tool` including `UrlContext` to instruct Gemini to include the referenced web addresses in the prompt, then construct an answer based on the content provided."
      ],
      "metadata": {
        "id": "b95FCfxwIDLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Url context tool\n",
        "url_context_tool = Tool(url_context=UrlContext)\n",
        "url = \"https://conference.mscc.mu/\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model = MODEL_ID,\n",
        "    contents = f\"Give me a summary of {url}\",\n",
        "    config = GenerateContentConfig(\n",
        "        tools = [url_context_tool]\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "mm6sKUCxIeoQ",
        "outputId": "5eac7c88-888b-48e6-a619-ccaa5e7440c9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The Developers Conference 2025, hosted by the Mauritius Software Craftsmanship Community (MSCC), will take place on July 24, 25, and 26 at the Voilà Hotel, Bagatelle. This event will feature workshops, panel discussions, and speaker sessions covering industry trends, best practices, and new innovations. Attendees can expect a friendly atmosphere with activities and networking opportunities. Major sponsors include SWAN, Google, and Microsoft. While the conference registration does not include meals, attendees can book and pay for lunch options separately."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inspect url context metadata**\n",
        "\n",
        "When the model uses URLs to inform its answer, the response object will contain\n",
        "`url_context_metadata`. This metadata lists the URLs the model retrieved and the status of that retrieval.\n",
        "\n",
        "You can inspect this metadata to confirm which sources were used, as shown in the code example below. Inspecting this metadata is useful for debugging which sources were successfully retrieved or for verifying the model's information sources.\n"
      ],
      "metadata": {
        "id": "2rQ5ymDtWlCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For verification, you can inspect the metadata to see which URLs the model retrieved\n",
        "print(response.candidates[0].url_context_metadata)"
      ],
      "metadata": {
        "id": "Hf38yzZ2WojZ",
        "outputId": "5f78cc81-8242-458a-a931-6cfe9be61244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "url_metadata=[UrlMetadata(\n",
            "  retrieved_url='https://conference.mscc.mu/',\n",
            "  url_retrieval_status=<UrlRetrievalStatus.URL_RETRIEVAL_STATUS_SUCCESS: 'URL_RETRIEVAL_STATUS_SUCCESS'>\n",
            ")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BsP0vXOY7hg"
      },
      "source": [
        "## Search as a tool (Grounding)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "[Grounding](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini) lets you connect real-world data to the Gemini model.\n",
        "\n",
        "By grounding model responses in Google Search results, the model can access information at runtime that goes beyond its training data which can produce more accurate, up-to-date, and relevant responses.\n",
        "\n",
        "Using Grounding with Google Search, you can improve the accuracy and recency of responses from the model. Starting with Gemini 2.0, Google Search is available as a tool. This means that the model can decide when to use Google Search.\n",
        "\n",
        "For more examples of Grounding, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_M_4RRBdO_3"
      },
      "source": [
        "### Google Search\n",
        "\n",
        "You can add the `tools` keyword argument with a `Tool` including `GoogleSearch` to instruct Gemini to first perform a Google Search with the prompt, then construct an answer based on the web search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "yeR09J3AZT4U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "25c31c4a-4db8-4e9a-871e-c7274a03975d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "As of Tuesday, September 2, 2025 in Austin, TX, the current temperature is approximately 94°F (34°C). However, different sources provide slightly varying real-time temperatures.\n\nAccording to one source, the temperature feels like 95°F (35°C) with partly cloudy skies. Another report indicates a current temperature of 91°F with a \"RealFeel\" of 99°F. A local news outlet, KVUE, reported the temperature to be 96°F around 4-5 PM. Meanwhile, the temperature at Austin-Bergstrom International Airport was reported as 83°F under sunny skies.\n\nThe forecast for the rest of the day indicates that temperatures will gradually decrease into the evening, with lows expected to be in the mid-70s."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "google_maps_widget_context_token=None grounding_chunks=[GroundingChunk(\n",
            "  web=GroundingChunkWeb(\n",
            "    domain='google.com',\n",
            "    title='Weather information for Austin, TX, US',\n",
            "    uri='https://www.google.com/search?q=weather+in+Austin, TX,+US'\n",
            "  )\n",
            "), GroundingChunk(\n",
            "  web=GroundingChunkWeb(\n",
            "    domain='accuweather.com',\n",
            "    title='accuweather.com',\n",
            "    uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHEZ_oqLsycRb5oWhp3qKxSMi49bX4rhJo5GZaTbuKtNYYrGJEO-8OptkfK9oEANnMCDW61TIBxf8FBdy1lBy9ZSW80IF8TTMPHrdjDQ3VMq7OxL3WgUjLW2JF6ToqbofJPvUrTfdNQ_SUAm2V_6cCovAEyw4lXzX3NgFMhaDCSIQ=='\n",
            "  )\n",
            "), GroundingChunk(\n",
            "  web=GroundingChunkWeb(\n",
            "    domain='kvue.com',\n",
            "    title='kvue.com',\n",
            "    uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEue3m_vyWyxBFAmNT7YbO7bE9dDLc200Z3hX7vq9z6OTsPgrfF1zV5x72R9lzjxSherIRJ2c6B678LRO-hNHeqDAErxnyvGX728ASY_yULfkiQkXIbw-sW'\n",
            "  )\n",
            "), GroundingChunk(\n",
            "  web=GroundingChunkWeb(\n",
            "    domain='timeanddate.com',\n",
            "    title='timeanddate.com',\n",
            "    uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHJqB8kHAkQCIegEGMD3cpbckOZaja7v_Wvx7lLXKPEMyeWVzXOwPu6gFx8A-CzworBdKX8FQdzthWBTQFAUB74pAUSOXnAzZ0uWP-1ifkBUiAKWuh8U7CihVprFFlZYT6gH7sseOEhLlE='\n",
            "  )\n",
            ")] grounding_supports=[GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    0,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=103,\n",
            "    text='As of Tuesday, September 2, 2025 in Austin, TX, the current temperature is approximately 94°F (34°C).'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    0,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=272,\n",
            "    start_index=181,\n",
            "    text='According to one source, the temperature feels like 95°F (35°C) with partly cloudy skies.'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    1,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=356,\n",
            "    start_index=273,\n",
            "    text='Another report indicates a current temperature of 91°F with a \"RealFeel\" of 99°F.'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    2,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=435,\n",
            "    start_index=357,\n",
            "    text='A local news outlet, KVUE, reported the temperature to be 96°F around 4-5 PM.'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    3,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=545,\n",
            "    start_index=436,\n",
            "    text='Meanwhile, the temperature at Austin-Bergstrom International Airport was reported as 83°F under sunny skies.'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    0,\n",
            "    2,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=694,\n",
            "    start_index=547,\n",
            "    text='The forecast for the rest of the day indicates that temperatures will gradually decrease into the evening, with lows expected to be in the mid-70s.'\n",
            "  )\n",
            ")] retrieval_metadata=RetrievalMetadata() retrieval_queries=None search_entry_point=SearchEntryPoint(\n",
            "  rendered_content=\"\"\"<style>\n",
            ".container {\n",
            "  align-items: center;\n",
            "  border-radius: 8px;\n",
            "  display: flex;\n",
            "  font-family: Google Sans, Roboto, sans-serif;\n",
            "  font-size: 14px;\n",
            "  line-height: 20px;\n",
            "  padding: 8px 12px;\n",
            "}\n",
            ".chip {\n",
            "  display: inline-block;\n",
            "  border: solid 1px;\n",
            "  border-radius: 16px;\n",
            "  min-width: 14px;\n",
            "  padding: 5px 16px;\n",
            "  text-align: center;\n",
            "  user-select: none;\n",
            "  margin: 0 8px;\n",
            "  -webkit-tap-highlight-color: transparent;\n",
            "}\n",
            ".carousel {\n",
            "  overflow: auto;\n",
            "  scrollbar-width: none;\n",
            "  white-space: nowrap;\n",
            "  margin-right: -12px;\n",
            "}\n",
            ".headline {\n",
            "  display: flex;\n",
            "  margin-right: 4px;\n",
            "}\n",
            ".gradient-container {\n",
            "  position: relative;\n",
            "}\n",
            ".gradient {\n",
            "  position: absolute;\n",
            "  transform: translate(3px, -9px);\n",
            "  height: 36px;\n",
            "  width: 9px;\n",
            "}\n",
            "@media (prefers-color-scheme: light) {\n",
            "  .container {\n",
            "    background-color: #fafafa;\n",
            "    box-shadow: 0 0 0 1px #0000000f;\n",
            "  }\n",
            "  .headline-label {\n",
            "    color: #1f1f1f;\n",
            "  }\n",
            "  .chip {\n",
            "    background-color: #ffffff;\n",
            "    border-color: #d2d2d2;\n",
            "    color: #5e5e5e;\n",
            "    text-decoration: none;\n",
            "  }\n",
            "  .chip:hover {\n",
            "    background-color: #f2f2f2;\n",
            "  }\n",
            "  .chip:focus {\n",
            "    background-color: #f2f2f2;\n",
            "  }\n",
            "  .chip:active {\n",
            "    background-color: #d8d8d8;\n",
            "    border-color: #b6b6b6;\n",
            "  }\n",
            "  .logo-dark {\n",
            "    display: none;\n",
            "  }\n",
            "  .gradient {\n",
            "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
            "  }\n",
            "}\n",
            "@media (prefers-color-scheme: dark) {\n",
            "  .container {\n",
            "    background-color: #1f1f1f;\n",
            "    box-shadow: 0 0 0 1px #ffffff26;\n",
            "  }\n",
            "  .headline-label {\n",
            "    color: #fff;\n",
            "  }\n",
            "  .chip {\n",
            "    background-color: #2c2c2c;\n",
            "    border-color: #3c4043;\n",
            "    color: #fff;\n",
            "    text-decoration: none;\n",
            "  }\n",
            "  .chip:hover {\n",
            "    background-color: #353536;\n",
            "  }\n",
            "  .chip:focus {\n",
            "    background-color: #353536;\n",
            "  }\n",
            "  .chip:active {\n",
            "    background-color: #464849;\n",
            "    border-color: #53575b;\n",
            "  }\n",
            "  .logo-light {\n",
            "    display: none;\n",
            "  }\n",
            "  .gradient {\n",
            "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
            "  }\n",
            "}\n",
            "</style>\n",
            "<div class=\"container\">\n",
            "  <div class=\"headline\">\n",
            "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
            "    </svg>\n",
            "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
            "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
            "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
            "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
            "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
            "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
            "    </svg>\n",
            "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
            "  </div>\n",
            "  <div class=\"carousel\">\n",
            "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHyaoI5ArmgzfMW4QbwT8_RjX5vQTVrN43-BgqwsKfSjzHxBBKycKaV0HXz40IjPdiQ6miz4qNIJEZWFnAELhZ9_XFmkmk_zZbWoY9Vzd9jWEQVYRtrzE9v_oEHU0hgoe13PCMW4tdgAtDaJIIhkatJFBqnnLZ_CWyNLAXe60k1qZfMu8kNczkdlpmh3_ZueJMiOgNi0vgZKqEB9o9OdxHB1AuP8w==\">current temperature in Austin, TX</a>\n",
            "  </div>\n",
            "</div>\n",
            "\"\"\"\n",
            ") web_search_queries=['current temperature in Austin, TX']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".container {\n",
              "  align-items: center;\n",
              "  border-radius: 8px;\n",
              "  display: flex;\n",
              "  font-family: Google Sans, Roboto, sans-serif;\n",
              "  font-size: 14px;\n",
              "  line-height: 20px;\n",
              "  padding: 8px 12px;\n",
              "}\n",
              ".chip {\n",
              "  display: inline-block;\n",
              "  border: solid 1px;\n",
              "  border-radius: 16px;\n",
              "  min-width: 14px;\n",
              "  padding: 5px 16px;\n",
              "  text-align: center;\n",
              "  user-select: none;\n",
              "  margin: 0 8px;\n",
              "  -webkit-tap-highlight-color: transparent;\n",
              "}\n",
              ".carousel {\n",
              "  overflow: auto;\n",
              "  scrollbar-width: none;\n",
              "  white-space: nowrap;\n",
              "  margin-right: -12px;\n",
              "}\n",
              ".headline {\n",
              "  display: flex;\n",
              "  margin-right: 4px;\n",
              "}\n",
              ".gradient-container {\n",
              "  position: relative;\n",
              "}\n",
              ".gradient {\n",
              "  position: absolute;\n",
              "  transform: translate(3px, -9px);\n",
              "  height: 36px;\n",
              "  width: 9px;\n",
              "}\n",
              "@media (prefers-color-scheme: light) {\n",
              "  .container {\n",
              "    background-color: #fafafa;\n",
              "    box-shadow: 0 0 0 1px #0000000f;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #1f1f1f;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #ffffff;\n",
              "    border-color: #d2d2d2;\n",
              "    color: #5e5e5e;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #d8d8d8;\n",
              "    border-color: #b6b6b6;\n",
              "  }\n",
              "  .logo-dark {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
              "  }\n",
              "}\n",
              "@media (prefers-color-scheme: dark) {\n",
              "  .container {\n",
              "    background-color: #1f1f1f;\n",
              "    box-shadow: 0 0 0 1px #ffffff26;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #fff;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #2c2c2c;\n",
              "    border-color: #3c4043;\n",
              "    color: #fff;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #464849;\n",
              "    border-color: #53575b;\n",
              "  }\n",
              "  .logo-light {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
              "  }\n",
              "}\n",
              "</style>\n",
              "<div class=\"container\">\n",
              "  <div class=\"headline\">\n",
              "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
              "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
              "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
              "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
              "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
              "  </div>\n",
              "  <div class=\"carousel\">\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHyaoI5ArmgzfMW4QbwT8_RjX5vQTVrN43-BgqwsKfSjzHxBBKycKaV0HXz40IjPdiQ6miz4qNIJEZWFnAELhZ9_XFmkmk_zZbWoY9Vzd9jWEQVYRtrzE9v_oEHU0hgoe13PCMW4tdgAtDaJIIhkatJFBqnnLZ_CWyNLAXe60k1qZfMu8kNczkdlpmh3_ZueJMiOgNi0vgZKqEB9o9OdxHB1AuP8w==\">current temperature in Austin, TX</a>\n",
              "  </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "google_search_tool = Tool(google_search=GoogleSearch())\n",
        "thinking_config = ThinkingConfig(thinking_budget=1024)\n",
        "        # Turn off thinking:\n",
        "        # thinking_config=ThinkingConfig(thinking_budget=0)\n",
        "        # Turn on dynamic thinking:\n",
        "        # thinking_config=ThinkingConfig(thinking_budget=-1)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is the current temperature in Austin, TX?\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[google_search_tool],\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))\n",
        "\n",
        "print(response.candidates[0].grounding_metadata)\n",
        "\n",
        "HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0pb-Kh1xEHU"
      },
      "source": [
        "## Function calling\n",
        "\n",
        "[Function Calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling) in Gemini lets developers create a description of a function in their code, then pass that description to a language model in a request.\n",
        "\n",
        "You can submit a Python function for automatic function calling, which will run the function and return the output in natural language generated by Gemini.\n",
        "\n",
        "You can also submit an [OpenAPI Specification](https://www.openapis.org/) which will respond with the name of a function that matches the description and the arguments to call it with.\n",
        "\n",
        "For more examples of Function calling with Gemini, check out this notebook: [Intro to Function Calling with Gemini](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/intro_function_calling.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSUWWlrrlR-D"
      },
      "source": [
        "### Python Function (Automatic Function Calling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "aRR8HZhLlR-E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "4c0006f3-d618-4182-e212-fb391ac207d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Which San Francisco are you referring to? San Francisco, CA? San Francisco, DE? etc."
          },
          "metadata": {}
        }
      ],
      "source": [
        "def get_current_weather(location: str) -> str:\n",
        "    \"\"\"Example method. Returns the current weather.\n",
        "\n",
        "    Args:\n",
        "        location: The city and state, e.g. San Francisco, CA\n",
        "    \"\"\"\n",
        "    weather_map: dict[str, str] = {\n",
        "        \"Boston, MA\": \"snowing\",\n",
        "        \"San Francisco, CA\": \"foggy\",\n",
        "        \"Seattle, WA\": \"raining\",\n",
        "        \"Austin, TX\": \"hot\",\n",
        "        \"Chicago, IL\": \"windy\",\n",
        "    }\n",
        "    return weather_map.get(location, \"unknown\")\n",
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is the weather like in San Francisco?\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[get_current_weather],\n",
        "        temperature=0,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4syyLEClGcn"
      },
      "source": [
        "### OpenAPI Specification (Manual Function Calling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "2BDQPwgcxRN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33090e70-fd3e-416e-8eba-238fe640bf54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id=None args={'destination': 'Paris'} name='get_destination'\n"
          ]
        }
      ],
      "source": [
        "get_destination = FunctionDeclaration(\n",
        "    name=\"get_destination\",\n",
        "    description=\"Get the destination that the user wants to go to\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"destination\": {\n",
        "                \"type\": \"STRING\",\n",
        "                \"description\": \"Destination that the user wants to go to\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "destination_tool = Tool(\n",
        "    function_declarations=[get_destination],\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"I'd like to travel to Paris.\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[destination_tool],\n",
        "        temperature=0,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.function_calls[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhDs2X3o0neK"
      },
      "source": [
        "## Code Execution\n",
        "\n",
        "The Gemini API [code execution](https://ai.google.dev/gemini-api/docs/code-execution?lang=python) feature enables the model to generate and run Python code and learn iteratively from the results until it arrives at a final output. You can use this code execution capability to build applications that benefit from code-based reasoning and that produce text output. For example, you could use code execution in an application that solves equations or processes text.\n",
        "\n",
        "The Gemini API provides code execution as a tool, similar to function calling.\n",
        "After you add code execution as a tool, the model decides when to use it.\n",
        "\n",
        "For more examples of Code Execution, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/code-execution/intro_code_execution.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "1W-3c7sy0nyz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "6fdb3bb8-7da0-4a32-f703-c2befce227f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Code\n\n```py\ndef fibonacci(n):\n    if n <= 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        a, b = 0, 1\n        for _ in range(2, n + 1):\n            a, b = b, a + b\n        return b\n\nfib_20 = fibonacci(20)\nprint(f\"The 20th Fibonacci number is: {fib_20}\")\n\n```\n\n### Output\n\n```\nThe 20th Fibonacci number is: 6765\n\n```\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "code_execution_tool = Tool(code_execution=ToolCodeExecution())\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Calculate 20th fibonacci number. Then find the nearest palindrome to it.\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[code_execution_tool],\n",
        "        temperature=0,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(\n",
        "    Markdown(\n",
        "        f\"\"\"\n",
        "## Code\n",
        "\n",
        "```py\n",
        "{response.executable_code}\n",
        "```\n",
        "\n",
        "### Output\n",
        "\n",
        "```\n",
        "{response.code_execution_result}\n",
        "```\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQwiONFdVHw5"
      },
      "source": [
        "## What's next\n",
        "\n",
        "- See the [Google Gen AI SDK reference docs](https://googleapis.github.io/python-genai/).\n",
        "- Explore other notebooks in the [Google Cloud Generative AI GitHub repository](https://github.com/GoogleCloudPlatform/generative-ai).\n",
        "- Explore AI models in [Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_gemini_2_5_pro.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}